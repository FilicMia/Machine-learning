{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "import numpy as np\n",
    "\n",
    "class gmmhmm:\n",
    "    #This class converted with modifications from https://code.google.com/p/hmm-speech-recognition/source/browse/Word.m\n",
    "    def __init__(self, n_states):\n",
    "        self.n_states = n_states\n",
    "        #PSEUDO RANDOM GENERATOR WITH seed equal to 0.\n",
    "        self.random_state = np.random.RandomState(0)\n",
    "        \n",
    "        #Normalize random initial state\n",
    "                    #Random values in a given shape. self.n_states* 1\n",
    "            #set initial states distribution as well as initiaj Bj distribution\n",
    "            #of values due to the certain state.\n",
    "        self.prior = self._normalize(self.random_state.rand(self.n_states, 1))\n",
    "        self.A = self._stochasticize(self.random_state.rand(self.n_states, self.n_states))\n",
    "        \n",
    "        self.mu = None\n",
    "        self.covs = None\n",
    "        self.n_dims = None\n",
    "           \n",
    "    def _forward(self, B):\n",
    "        log_likelihood = 0.\n",
    "        T = B.shape[1]\n",
    "        alpha = np.zeros(B.shape)\n",
    "        for t in range(T):\n",
    "            if t == 0:\n",
    "                alpha[:, t] = B[:, t] * self.prior.ravel()\n",
    "            else:\n",
    "                alpha[:, t] = B[:, t] * np.dot(self.A.T, alpha[:, t - 1])\n",
    "         \n",
    "            alpha_sum = np.sum(alpha[:, t])\n",
    "            alpha[:, t] /= alpha_sum\n",
    "            log_likelihood = log_likelihood + np.log(alpha_sum)\n",
    "        return log_likelihood, alpha\n",
    "    \n",
    "    def _backward(self, B):\n",
    "        T = B.shape[1]\n",
    "        beta = np.zeros(B.shape);\n",
    "           \n",
    "        beta[:, -1] = np.ones(B.shape[0])\n",
    "            \n",
    "        for t in range(T - 1)[::-1]:\n",
    "            beta[:, t] = np.dot(self.A, (B[:, t + 1] * beta[:, t + 1]))\n",
    "            beta[:, t] /= np.sum(beta[:, t])\n",
    "        return beta\n",
    "    #indicates that you shouldnt do this.\n",
    "    def _state_likelihood(self, obs):\n",
    "        obs = np.atleast_2d(obs)\n",
    "        B = np.zeros((self.n_states, obs.shape[1]))\n",
    "        for s in range(self.n_states):\n",
    "            #Needs scipy 0.14\n",
    "            np.random.seed(self.random_state.randint(1))\n",
    "            B[s, :] = st.multivariate_normal.pdf(\n",
    "                obs.T, mean=self.mu[:, s].T, cov=self.covs[:, :, s].T)\n",
    "            #This function can (and will!) return values >> 1\n",
    "            #See the discussion here for the equivalent matlab function\n",
    "            #https://groups.google.com/forum/#!topic/comp.soft-sys.matlab/YksWK0T74Ak\n",
    "            #Key line: \"Probabilities have to be less than 1,\n",
    "            #Densities can be anything, even infinite (at individual points).\"\n",
    "            #This is evaluating the density at individual points...\n",
    "        return B\n",
    "    \n",
    "    def _normalize(self, x):\n",
    "        return (x + (x == 0)) / np.sum(x)\n",
    "    \n",
    "    def _stochasticize(self, x):\n",
    "        return (x + (x == 0)) / np.sum(x, axis=1)\n",
    "    \n",
    "    def _em_init(self, obs):\n",
    "        #Using this _em_init function allows for less required constructor args.\n",
    "        if self.n_dims is None:\n",
    "            self.n_dims = obs.shape[0]\n",
    "        if self.mu is None:\n",
    "            subset = self.random_state.choice(np.arange(self.n_dims), size=self.n_states, replace=False)\n",
    "           # print(self.n_dims)\n",
    "            self.mu = obs[:,subset]\n",
    "        if self.covs is None:\n",
    "            self.covs = np.zeros((self.n_dims, self.n_dims, self.n_states))\n",
    "            self.covs += np.diag(np.diag(np.cov(obs)))[:, :, None]\n",
    "        return self\n",
    "    \n",
    "    def _em_step(self, obs): \n",
    "        obs = np.atleast_2d(obs)\n",
    "        B = self._state_likelihood(obs)\n",
    "        T = obs.shape[1]\n",
    "        \n",
    "        log_likelihood, alpha = self._forward(B)\n",
    "        beta = self._backward(B)\n",
    "        \n",
    "        xi_sum = np.zeros((self.n_states, self.n_states))\n",
    "        gamma = np.zeros((self.n_states, T))\n",
    "        \n",
    "        for t in range(T - 1):\n",
    "            partial_sum = self.A * np.dot(alpha[:, t], (beta[:, t] * B[:, t + 1]).T)\n",
    "            xi_sum += self._normalize(partial_sum)\n",
    "            partial_g = alpha[:, t] * beta[:, t]\n",
    "            gamma[:, t] = self._normalize(partial_g)\n",
    "              \n",
    "        partial_g = alpha[:, -1] * beta[:, -1]\n",
    "        gamma[:, -1] = self._normalize(partial_g)\n",
    "        \n",
    "        expected_prior = gamma[:, 0]\n",
    "        expected_A = self._stochasticize(xi_sum)\n",
    "        \n",
    "        expected_mu = np.zeros((self.n_dims, self.n_states))\n",
    "        expected_covs = np.zeros((self.n_dims, self.n_dims, self.n_states))\n",
    "        \n",
    "        gamma_state_sum = np.sum(gamma, axis=1)\n",
    "        #Set zeros to 1 before dividing\n",
    "        gamma_state_sum = gamma_state_sum + (gamma_state_sum == 0)\n",
    "        \n",
    "        for s in range(self.n_states):\n",
    "            gamma_obs = obs * gamma[s, :]\n",
    "            expected_mu[:, s] = np.sum(gamma_obs, axis=1) / gamma_state_sum[s]\n",
    "            partial_covs = np.dot(gamma_obs, obs.T) / gamma_state_sum[s] - np.dot(expected_mu[:, s], expected_mu[:, s].T)\n",
    "            #Symmetrize\n",
    "            partial_covs = np.triu(partial_covs) + np.triu(partial_covs).T - np.diag(partial_covs)\n",
    "        \n",
    "        #Ensure positive semidefinite by adding diagonal loading\n",
    "        expected_covs += .01 * np.eye(self.n_dims)[:, :, None]\n",
    "        \n",
    "        self.prior = expected_prior\n",
    "        self.mu = expected_mu\n",
    "        self.covs = expected_covs\n",
    "        self.A = expected_A\n",
    "        return log_likelihood\n",
    "    \n",
    "    def fit(self, obs, n_iter=15):\n",
    "        #Support for 2D and 3D arrays\n",
    "        #2D should be n_features, n_dims\n",
    "        #3D should be n_examples, n_features, n_dims\n",
    "        #For example, with 6 features per speech segment, 105 different words\n",
    "        #this array should be size\n",
    "        #(105, 6, X) where X is the number of frames with features extracted\n",
    "        #For a single example file, the array should be size (6, X)\n",
    "        if len(obs.shape) == 2:\n",
    "            for i in range(n_iter):\n",
    "                self._em_init(obs)\n",
    "                log_likelihood = self._em_step(obs)\n",
    "        elif len(obs.shape) == 3:\n",
    "            count = obs.shape[0]\n",
    "            for n in range(count):\n",
    "                for i in range(n_iter):\n",
    "                    self._em_init(obs[n, :, :])\n",
    "                    log_likelihood = self._em_step(obs[n, :, :])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, obs):\n",
    "        #Support for 2D and 3D arrays\n",
    "        #2D should be n_features, n_dims\n",
    "        #3D should be n_examples, n_features, n_dims\n",
    "        #For example, with 6 features per speech segment, 105 different words\n",
    "        #this array should be size\n",
    "        #(105, 6, X) where X is the number of frames with features extracted\n",
    "        #For a single example file, the array should be size (6, X)\n",
    "        if len(obs.shape) == 2:\n",
    "            B = self._state_likelihood(obs)\n",
    "            log_likelihood, _ = self._forward(B)\n",
    "            return log_likelihood\n",
    "        elif len(obs.shape) == 3:\n",
    "            count = obs.shape[0]\n",
    "            out = np.zeros((count,))\n",
    "            for n in range(count):\n",
    "                B = self._state_likelihood(obs[n, :, :])\n",
    "                log_likelihood, _ = self._forward(B)\n",
    "                out[n] = log_likelihood\n",
    "            return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
